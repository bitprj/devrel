**[Step-By-Step Technical Blog Guide](https://hq.bitproject.org/how-to-write-a-technical-blog/)**

### :pushpin: Step 1
**TITLE:**    
Scraping and Sanitizing [Big Data] Using Beautiful Soup

**TOPIC:**    
Big Data

**DESCRIPTION (5-7+ sentences):**    
I will create a tutorial for a basic web scraper using the Beautiful Soup library in Python. I was considering using sports statistics like this https://news.codecademy.com/web-scraping-python-beautiful-soup-mlb-stats/. May use custom data set with some NULL values to also show how to crate clean looking data. The emphasis will be on how to analyze the web tagging for a page that is crucial for scraping, as it is likely someone scraping data will have more experience using Python and data science tools but not be experienced with web development. Would try and show how to make a scraper capable of "crawling" across multiple webpages so that we could get multiple pages of data if needed.

### :pushpin: Step 2
:family: **TARGET AUDIENCE (3-5+ sentences):**    
This is a blog aimed towards people who may have experience with Python, but are unsure about how to approach gathering data from websites. Often, data scientists are given their data from AI scrapers or third parties in general, so being able to directly extract and verify your own data adds trust to your own work. It will be assumed that there is little experience with HTML and tagging.

### :pushpin: Step 3
> Outline your learning/teaching structure: 

**Beginning (2-3+ sentences):**    
Begin by explaining the benefits of scraping your own data (verification, flexibility, etc), Then, would provide more background on the technical tools used like Beautiful Soup. Will also outline any packages that need to be installed.

**Middle (2-3+ sentences):**    
First, would find a website to scrape data from and store that in our program. Then, provide thorough explanation of how to inspect element and determine what you will want to use in your code, as well as point out certain patterns to help make things easy to identify. Would then show how you can verify in your code if you extracted the right information and display it in a plain text format that is easier to understand.

**End (2-3+ sentences):**    
Would show how to store relevant data into dataframe and save it into a spreadsheet that could be used for data analysis. Would create set of code to extract single webpage, then show any potential formatting clues to go over multiple pages of a website (eg shopping on Amazon). Would then try and showcase instances of dirty data and what could be done to identify it.
